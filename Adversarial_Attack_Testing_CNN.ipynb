{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial_Attack_Testing_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "efa26081"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import cv2\n",
        "import tqdm.notebook as tq\n",
        "from PIL import Image\n",
        "import keras.backend as K\n",
        "import pickle\n",
        "import keras\n",
        "from keras.models import load_model\n",
        "import glob\n",
        "import os\n",
        "import ntpath"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93U1N3jKzCoj"
      },
      "source": [
        "data_location = 'Dataset/carla_dataset/'\n",
        "model_location = 'Models/'\n",
        "noise_location = data_location"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2CGfYeek42P"
      },
      "source": [
        "model = load_model(model_location + 'model.h5')\n",
        "\n",
        "with open(model_location + 'mean_image_rgb.pickle', 'rb') as f:\n",
        "    mean = pickle.load(f, encoding='latin1')  \n",
        "\n",
        "path_to_weights = model_location + 'yolov3-spp.weights'\n",
        "path_to_cfg = model_location + 'yolov3-spp.cfg'\n",
        "\n",
        "network = cv2.dnn.readNetFromDarknet(path_to_cfg, path_to_weights)\n",
        "\n",
        "network.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "network.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)\n",
        "\n",
        "layers_all = network.getLayerNames()\n",
        "layers_names_output = [layers_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
        "probability_minimum = 0.2\n",
        "threshold = 0.2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcUpqNH2kEsU"
      },
      "source": [
        "def detect_sign(input_image):\n",
        "    image_BGR = cv2.imread(input_image)\n",
        "    h, w = image_BGR.shape[:2]\n",
        "    blob = cv2.dnn.blobFromImage(image_BGR, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "\n",
        "    network.setInput(blob)\n",
        "    output_from_network = network.forward(layers_names_output)\n",
        "\n",
        "    bounding_boxes = []\n",
        "    confidences = []\n",
        "    for result in output_from_network:\n",
        "        for detected_objects in result:\n",
        "            scores = detected_objects[5:]\n",
        "            class_current = np.argmax(scores)\n",
        "            confidence_current = scores[class_current]\n",
        "\n",
        "            if confidence_current > probability_minimum:\n",
        "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
        "\n",
        "                x_center, y_center, box_width, box_height = box_current\n",
        "                x_min = int(x_center - (box_width / 2))\n",
        "                y_min = int(y_center - (box_height / 2))\n",
        "\n",
        "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
        "                confidences.append(float(confidence_current))\n",
        "\n",
        "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
        "\n",
        "    detected_sign = []\n",
        "    if len(results) > 0:\n",
        "        for i in results.flatten():\n",
        "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
        "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
        "            c_ts = image_BGR[y_min:y_min+int(box_height), x_min:x_min+int(box_width), :]\n",
        "            if c_ts.shape[:1] == (0,) or c_ts.shape[1:2] == (0,):\n",
        "                pass\n",
        "            else:\n",
        "                blob_ts = cv2.dnn.blobFromImage(c_ts, 1 / 255.0, size=(32, 32), swapRB=True, crop=False)\n",
        "                blob_ts[0] = blob_ts[0, :, :, :] - mean['mean_image_rgb']\n",
        "                blob_ts = blob_ts.transpose(0, 2, 3, 1)\n",
        "                bolb_ts = np.clip(blob_ts[0], 0.0, 1.0)\n",
        "                \n",
        "                plt.imsave(input_image.replace('.jpg', '_detect.png'), bolb_ts)\n",
        "                time.sleep(5)\n",
        "                X_test = []\n",
        "                image = Image.open(input_image.replace('.jpg', '_detect.png'))\n",
        "                image = image.resize((30, 30))\n",
        "                if image.mode == 'RGBA':\n",
        "                    image.load() \n",
        "                    background = Image.new(\"RGB\", image.size, (255, 255, 255))\n",
        "                    background.paste(image, mask=image.split()[3])\n",
        "                    image = np.array(background)\n",
        "                else:\n",
        "                    image = np.array(image)\n",
        "                X_test.append(image)\n",
        "                X_test = np.array(X_test)\n",
        "                scores = np.argmax(model.predict(X_test), axis=-1)\n",
        "                if scores[0] in range(3):\n",
        "                    box_info = (x_min, y_min, x_min+box_width, y_min+box_height)\n",
        "                    detected_sign.append((X_test, scores[0], box_info))\n",
        "                    break\n",
        "    return detected_sign"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuVk1Rhst6in"
      },
      "source": [
        "class CarSimulatorAdv(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(CarSimulatorAdv, self).__init__()\n",
        "    self.classifier = load_model(model_location+'model.h5')\n",
        "    with open(model_location+'mean_image_rgb.pickle', 'rb') as f:\n",
        "        self.mean = pickle.load(f, encoding='latin1')  # dictionary type\n",
        "    self.objectdetector = cv2.dnn.readNetFromDarknet(model_location+'yolov3-spp.cfg', model_location+'yolov3-spp.weights')\n",
        "    self.objectdetector.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)\n",
        "    self.objectdetector.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16)\n",
        "    self.layers_all = self.objectdetector.getLayerNames()\n",
        "    self.layers_names_output = [self.layers_all[i[0] - 1] for i in self.objectdetector.getUnconnectedOutLayers()]\n",
        "    self.probability_minimum = 0.2\n",
        "    self.threshold = 0.2\n",
        "\n",
        "  def call(self, input_image, training=False):\n",
        "    image_BGR = cv2.imread(input_image)\n",
        "    h, w = image_BGR.shape[:2]\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image_BGR, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
        "    self.objectdetector.setInput(blob)\n",
        "    output_from_network = self.objectdetector.forward(self.layers_names_output)\n",
        "\n",
        "    bounding_boxes = []\n",
        "    confidences = []\n",
        "\n",
        "    for result in output_from_network:\n",
        "        for detected_objects in result:\n",
        "            scores = detected_objects[5:]\n",
        "            class_current = np.argmax(scores)\n",
        "            confidence_current = scores[class_current]\n",
        "\n",
        "            if confidence_current > self.probability_minimum:\n",
        "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
        "                x_center, y_center, box_width, box_height = box_current\n",
        "                x_min = int(x_center - (box_width / 2))\n",
        "                y_min = int(y_center - (box_height / 2))\n",
        "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
        "                confidences.append(float(confidence_current))\n",
        "\n",
        "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, self.probability_minimum, self.threshold)\n",
        "\n",
        "    detected_sign = []\n",
        "    if len(results) > 0:\n",
        "        for i in results.flatten():\n",
        "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
        "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
        "            c_ts = image_BGR[y_min:y_min+int(box_height), x_min:x_min+int(box_width), :]\n",
        "            if c_ts.shape[:1] == (0,) or c_ts.shape[1:2] == (0,):\n",
        "                pass\n",
        "            else:\n",
        "                blob_ts = cv2.dnn.blobFromImage(c_ts, 1 / 255.0, size=(32, 32), swapRB=True, crop=False)\n",
        "                blob_ts[0] = blob_ts[0, :, :, :] - self.mean['mean_image_rgb']\n",
        "                blob_ts = blob_ts.transpose(0, 2, 3, 1)\n",
        "\n",
        "                if input_image[-4:] == '.png':\n",
        "                    input_image = input_image.replace('.png', '.jpg')\n",
        "                tf.keras.preprocessing.image.save_img(input_image.replace('.jpg', '_detect.png'), blob_ts[0], scale=True)\n",
        "                bolb_img = tf.keras.preprocessing.image.load_img(input_image.replace('.jpg', '_detect.png'), grayscale=False, color_mode='rgb', target_size=(30, 30, 3), interpolation='nearest')\n",
        "                bolb_ts = keras.preprocessing.image.img_to_array(bolb_img)\n",
        "                X_test = np.array([bolb_ts])\n",
        "                scores = np.argmax(self.classifier.predict(X_test), axis=-1)\n",
        "                #print(self.classifier.predict(X_test))\n",
        "                if scores[0] in range(3):\n",
        "                    box_info = (x_min, y_min, x_min+box_width, y_min+box_height)\n",
        "                    detected_sign.append((X_test, scores[0], box_info))\n",
        "                    break\n",
        "    return detected_sign\n",
        "\n",
        "modelAdv = CarSimulatorAdv()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YYkv84TmTgU"
      },
      "source": [
        "# set noise class variable to add the noise of that class\n",
        "noise_class = 2\n",
        "noise = Image.open(noise_location+'noise'+str(noise_class)+'.png')\n",
        "if noise.mode == 'RGBA':\n",
        "    noise.load() \n",
        "    background = Image.new(\"RGB\", noise.size, (255, 255, 255))\n",
        "    background.paste(noise, mask=noise.split()[3])\n",
        "    noise = np.array(background)\n",
        "else:\n",
        "    noise = np.array(noise) "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7t6ES80-oMMG"
      },
      "source": [
        "def generator(sign_image):\n",
        "    X = Image.open(sign_image)\n",
        "    X = X.resize((30, 30))\n",
        "    if X.mode == 'RGBA':\n",
        "        X.load() \n",
        "        background = Image.new(\"RGB\", X.size, (255, 255, 255))\n",
        "        background.paste(X, mask=X.split()[3])\n",
        "        X = np.array(background)\n",
        "    else:\n",
        "        X = np.array(X)\n",
        "    X_noise = X + noise\n",
        "    return X_noise"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e0VHlN93fP5"
      },
      "source": [
        "def image_mapper_adv(input_image, sign, box_info):\n",
        "    image_path = ntpath.basename(input_image)\n",
        "    imagebg = Image.open(input_image)\n",
        "    if imagebg.mode == 'RGBA':\n",
        "        imagebg.load() \n",
        "        background = Image.new(\"RGB\", imagebg.size, (255, 255, 255))\n",
        "        background.paste(imagebg, mask=imagebg.split()[3])\n",
        "        imagebg = np.array(background)\n",
        "    else:\n",
        "        imagebg = np.array(imagebg)\n",
        "\n",
        "    x1, y1, x2, y2 = box_info\n",
        "    X_noisy = Image.open(sign)\n",
        "    X_noisy = X_noisy.resize((x2-x1, y2-y1))\n",
        "    if X_noisy.mode == 'RGBA':\n",
        "        X_noisy.load() \n",
        "        background = Image.new(\"RGB\", X_noisy.size, (255, 255, 255))\n",
        "        background.paste(X_noisy, mask=X_noisy.split()[3])\n",
        "        X_noisy = np.array(background)\n",
        "    else:\n",
        "        X_noisy = np.array(X_noisy)\n",
        "    \n",
        "    imagebg[y1:y2, x1:x2] = X_noisy\n",
        "\n",
        "    tf.keras.preprocessing.image.save_img(input_image.replace(image_path, 'AdvImages/'+image_path.replace('.jpg', '_noisy.png')), imagebg, scale=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kPF7tkTpk7z"
      },
      "source": [
        "with open(data_location + 'carla_dataset_annotation.csv', 'r') as f:\n",
        "    lines = f.read().splitlines()\n",
        "    scores = {}\n",
        "    for l in lines:\n",
        "        x = l.split(',')\n",
        "        scores[x[0]] = x[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdTjN-qQlPTU"
      },
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "def generate_adv():\n",
        "    count = 0\n",
        "    img_count = 0\n",
        "    index = []\n",
        "    detect_count = 0\n",
        "    for image in glob.glob(os.path.join(data_location, '*.jpg')):\n",
        "        #print(img_count)\n",
        "        try:\n",
        "            detect = modelAdv(image)\n",
        "            if len(detect)>0:\n",
        "                detect_count+=1\n",
        "                image_path = ntpath.basename(image)\n",
        "                if int(scores[image_path]) == detect[-1][1]:\n",
        "                    sign_img = normalization_layer(detect[-1][0])\n",
        "                    noisy = generator(image.replace('.jpg', '_detect.png'))\n",
        "                    noisy_path = data_location + 'NoisySigns/'+image_path.replace('.jpg', '_noisysign.png')\n",
        "                    tf.keras.preprocessing.image.save_img(noisy_path, noisy, scale=True)\n",
        "                    image_mapper_adv(image, noisy_path, detect[-1][2])\n",
        "                    adv_detect = modelAdv(data_location +'AdvImages/'+image_path.replace('.jpg','_noisy.png'))\n",
        "                    if len(adv_detect)>0:\n",
        "                        print(image_path, detect[-1][1], adv_detect[-1][1])\n",
        "                        if int(scores[image_path]) != adv_detect[-1][1]:\n",
        "                            count+=1\n",
        "                            index.append(image_path)\n",
        "                # if img_count == 10:\n",
        "                #     break\n",
        "        except:\n",
        "            continue\n",
        "        img_count+=1\n",
        "    print(detect_count)\n",
        "    return count, index"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg5GpmmGpaTy"
      },
      "source": [
        "count = generate_adv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVOw-uX-qRtr"
      },
      "source": [
        "count[0], count[1]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}